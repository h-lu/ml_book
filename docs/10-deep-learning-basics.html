<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>深度学习基础 – 机器学习：从理论到Python实践</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./11-cnn.html" rel="next">
<link href="./09-model-evaluation-feature-engineering.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./10-deep-learning-basics.html">第五部分：深度学习初探</a></li><li class="breadcrumb-item"><a href="./10-deep-learning-basics.html"><span class="chapter-title">深度学习基础</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">机器学习：从理论到Python实践</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">欢迎学习《机器学习：从理论到Python实践》</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">第一部分：机器学习基石与Python生态</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-introduction.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">机器学习导论</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-environment.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Python机器学习环境与核心库</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">第二部分：监督学习</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">回归与线性模型</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-classification-logreg-knn.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">分类与逻辑回归、KNN</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-svm.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">支持向量机 (SVM)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-decision-trees-ensemble-learning.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">决策树与集成学习</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">第三部分：无监督学习</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-clustering.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">聚类分析</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08-dimensionality-reduction.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">降维</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">第四部分：模型评估、优化与特征工程</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09-model-evaluation-feature-engineering.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">模型评估、优化与特征工程</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">第五部分：深度学习初探</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10-deep-learning-basics.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">深度学习基础</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11-cnn.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">卷积神经网络 (CNN)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12-rnn.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">循环神经网络 (RNN)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13-deep-learning-advanced.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">深度学习进阶</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">第六部分：强化学习入门</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14-reinforcement-learning.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">强化学习基础与应用</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">第七部分：综合项目与展望</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15-ml-project-workflow-summary.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">机器学习项目实战流程与总结</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./16-summary-outlook.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">课程总结与展望</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./appendices.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">附录</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#学习目标" id="toc-学习目标" class="nav-link active" data-scroll-target="#学习目标">学习目标</a></li>
  <li><a href="#从机器学习到深度学习" id="toc-从机器学习到深度学习" class="nav-link" data-scroll-target="#从机器学习到深度学习">10.1 从机器学习到深度学习</a></li>
  <li><a href="#神经网络基础" id="toc-神经网络基础" class="nav-link" data-scroll-target="#神经网络基础">10.2 神经网络基础</a>
  <ul class="collapse">
  <li><a href="#神经元模型-perceptron" id="toc-神经元模型-perceptron" class="nav-link" data-scroll-target="#神经元模型-perceptron">10.2.1 神经元模型 (Perceptron)</a></li>
  <li><a href="#激活函数-activation-functions" id="toc-激活函数-activation-functions" class="nav-link" data-scroll-target="#激活函数-activation-functions">10.2.2 激活函数 (Activation Functions)</a></li>
  <li><a href="#神经网络的结构" id="toc-神经网络的结构" class="nav-link" data-scroll-target="#神经网络的结构">10.2.3 神经网络的结构</a></li>
  </ul></li>
  <li><a href="#前向传播与反向传播" id="toc-前向传播与反向传播" class="nav-link" data-scroll-target="#前向传播与反向传播">10.3 前向传播与反向传播</a>
  <ul class="collapse">
  <li><a href="#前向传播-forward-propagation" id="toc-前向传播-forward-propagation" class="nav-link" data-scroll-target="#前向传播-forward-propagation">10.3.1 前向传播 (Forward Propagation)</a></li>
  <li><a href="#损失函数-loss-function" id="toc-损失函数-loss-function" class="nav-link" data-scroll-target="#损失函数-loss-function">10.3.2 损失函数 (Loss Function)</a></li>
  <li><a href="#反向传播-backward-propagation-与梯度下降" id="toc-反向传播-backward-propagation-与梯度下降" class="nav-link" data-scroll-target="#反向传播-backward-propagation-与梯度下降">10.3.3 反向传播 (Backward Propagation) 与梯度下降</a></li>
  </ul></li>
  <li><a href="#构建一个简单的神经网络-使用-kerastensorflow" id="toc-构建一个简单的神经网络-使用-kerastensorflow" class="nav-link" data-scroll-target="#构建一个简单的神经网络-使用-kerastensorflow">10.4 构建一个简单的神经网络 (使用 Keras/TensorFlow)</a>
  <ul class="collapse">
  <li><a href="#数据准备" id="toc-数据准备" class="nav-link" data-scroll-target="#数据准备">10.4.1 数据准备</a></li>
  <li><a href="#模型定义-使用-keras-sequential-api" id="toc-模型定义-使用-keras-sequential-api" class="nav-link" data-scroll-target="#模型定义-使用-keras-sequential-api">10.4.2 模型定义 (使用 Keras Sequential API)</a></li>
  <li><a href="#模型编译" id="toc-模型编译" class="nav-link" data-scroll-target="#模型编译">10.4.3 模型编译</a></li>
  <li><a href="#模型训练" id="toc-模型训练" class="nav-link" data-scroll-target="#模型训练">10.4.4 模型训练</a></li>
  <li><a href="#模型评估" id="toc-模型评估" class="nav-link" data-scroll-target="#模型评估">10.4.5 模型评估</a></li>
  <li><a href="#可视化决策边界-可选" id="toc-可视化决策边界-可选" class="nav-link" data-scroll-target="#可视化决策边界-可选">10.4.6 可视化决策边界 (可选)</a></li>
  </ul></li>
  <li><a href="#深度学习中的常见挑战" id="toc-深度学习中的常见挑战" class="nav-link" data-scroll-target="#深度学习中的常见挑战">10.5 深度学习中的常见挑战</a></li>
  <li><a href="#本章总结" id="toc-本章总结" class="nav-link" data-scroll-target="#本章总结">10.6 本章总结</a></li>
  <li><a href="#思考与练习" id="toc-思考与练习" class="nav-link" data-scroll-target="#思考与练习">10.7 思考与练习</a>
  <ul class="collapse">
  <li><a href="#基础概念回顾" id="toc-基础概念回顾" class="nav-link" data-scroll-target="#基础概念回顾">10.7.1 基础概念回顾</a></li>
  <li><a href="#keras实践与探索" id="toc-keras实践与探索" class="nav-link" data-scroll-target="#keras实践与探索">10.7.2 Keras实践与探索</a></li>
  <li><a href="#深入思考与挑战" id="toc-深入思考与挑战" class="nav-link" data-scroll-target="#深入思考与挑战">10.7.3 深入思考与挑战</a></li>
  <li><a href="#推荐阅读" id="toc-推荐阅读" class="nav-link" data-scroll-target="#推荐阅读">10.7.4 推荐阅读</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./10-deep-learning-basics.html">第五部分：深度学习初探</a></li><li class="breadcrumb-item"><a href="./10-deep-learning-basics.html"><span class="chapter-title">深度学习基础</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-title">深度学习基础</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="学习目标" class="level2">
<h2 class="anchored" data-anchor-id="学习目标">学习目标</h2>
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p><strong>学习目标：</strong></p>
<ul>
<li>理解深度学习的基本概念及其与机器学习的关系。</li>
<li>了解人工神经网络 (ANN) 的基本构成：神经元、激活函数、层次结构。</li>
<li>掌握常见的激活函数（如 Sigmoid, ReLU, Tanh, Softmax）及其特点。</li>
<li>理解前向传播 (Forward Propagation) 和反向传播 (Backward Propagation) 的基本原理。</li>
<li>了解损失函数 (Loss Function) 在神经网络训练中的作用以及常见的损失函数（如均方误差、交叉熵）。</li>
<li>理解梯度下降 (Gradient Descent) 及其变种（如SGD, Adam）在优化神经网络中的应用。</li>
<li>能够使用 Keras/TensorFlow 构建、编译、训练和评估一个简单的全连接神经网络。</li>
<li>初步了解深度学习中的常见挑战，如过拟合、梯度消失/爆炸。</li>
</ul>
</div>
</div>
</div>
</section>
<section id="从机器学习到深度学习" class="level2">
<h2 class="anchored" data-anchor-id="从机器学习到深度学习">10.1 从机器学习到深度学习</h2>
<p>在前面的章节中，我们学习了各种机器学习算法，它们在许多任务上都取得了显著的成功。然而，这些传统机器学习算法在处理复杂、高维度的数据（如图像、语音、自然语言）时，往往需要精心设计的特征工程。特征工程的好坏直接决定了模型的性能上限，但它本身既耗时又依赖领域知识。</p>
<p><strong>深度学习 (Deep Learning, DL)</strong> 作为机器学习的一个分支，试图解决这个问题。深度学习的核心思想是通过构建深层次的神经网络模型，自动从原始数据中学习有用的特征表示。这些模型通常包含多个处理层，每一层都会对输入数据进行非线性变换，并逐步提取出更抽象、更高级别的特征。</p>
<p><strong>与传统机器学习的关系：</strong></p>
<ul>
<li>深度学习是机器学习的一种方法。</li>
<li>传统机器学习算法通常是”浅层”的，而深度学习模型是”深层”的（通常指多个隐藏层）。</li>
<li>深度学习在图像识别、语音识别、自然语言处理等领域取得了突破性进展，主要是因为其强大的特征学习能力。</li>
</ul>
<p>“深度”指的是网络中包含多个隐藏层。这些隐藏层使得模型能够学习到数据中从简单到复杂的层次化特征。例如，在图像识别中，浅层可能学习边缘和角点，中层可能学习物体的部件，而深层则可能学习到完整的物体概念。</p>
<p>下图直观地展示了浅层学习和深度学习在特征提取上的区别：</p>
<div id="fig-deep-features" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-deep-features-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://cdn.prod.website-files.com/634e9d5d7cb8f7fc56b28199/66a2f1efb5b625f74538bd2a_668f001243b877277fd25aa1_652ebc26fbd9a45bcec81819_Deep_Learning_vs_Machine_Learning_3033723be2.jpeg" class="img-fluid figure-img" width="600">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-deep-features-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11.1: 浅层学习与深度学习特征提取对比 (图片来源: <a href="https://www.alltius.ai/glossary/what-is-deep-learning">Alltius</a>)
</figcaption>
</figure>
</div>
<div class="callout callout-style-simple callout-tip">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p><strong>深度学习的优势：</strong></p>
<ul>
<li><strong>自动特征学习</strong>：深度学习模型能够自动学习特征，减少对人工特征工程的依赖</li>
<li><strong>层次化特征提取</strong>：通过多层网络结构，可以学习从简单到复杂的层次化特征表示</li>
<li><strong>领域突破</strong>：在计算机视觉、语音识别、自然语言处理等领域实现了超越传统方法的性能</li>
</ul>
</div>
</div>
</div>
</section>
<section id="神经网络基础" class="level2">
<h2 class="anchored" data-anchor-id="神经网络基础">10.2 神经网络基础</h2>
<p>人工神经网络 (Artificial Neural Network, ANN) 是深度学习的核心。其灵感来源于生物神经系统，但经过了高度简化和数学化。</p>
<section id="神经元模型-perceptron" class="level3">
<h3 class="anchored" data-anchor-id="神经元模型-perceptron">10.2.1 神经元模型 (Perceptron)</h3>
<p>最简单的神经网络单元是<strong>感知机 (Perceptron)</strong>，或者更一般地称为<strong>神经元 (Neuron)</strong>。一个神经元接收若干个输入，对这些输入进行加权求和，然后通过一个<strong>激活函数 (Activation Function)</strong> 处理后产生输出。</p>
<div id="fig-neuron" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Neuron Model">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-neuron-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/10-deep-learning-basics/Perceptron-unit.svg" class="img-fluid figure-img" alt="Neuron Model" width="300">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-neuron-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11.2: 单个神经元模型
</figcaption>
</figure>
</div>
<p>对于一个有 <span class="math inline">\(n\)</span> 个输入的神经元：</p>
<ul>
<li>输入：<span class="math inline">\(x_1, x_2, \dots, x_n\)</span></li>
<li>权重：<span class="math inline">\(w_1, w_2, \dots, w_n\)</span></li>
<li>偏置：<span class="math inline">\(w_0\)</span> (通常记为 <span class="math inline">\(b\)</span>)</li>
</ul>
<ol type="1">
<li><strong>加权和 (Weighted Sum)：</strong> <span class="math inline">\(z = (w_1 x_1 + w_2 x_2 + \dots + w_n x_n) + b = \mathbf{w} \cdot \mathbf{x} + b\)</span></li>
<li><strong>激活 (Activation)：</strong> <span class="math inline">\(a = \sigma(z)\)</span>，其中 <span class="math inline">\(\sigma\)</span> 是激活函数。</li>
</ol>
<p>偏置项 <span class="math inline">\(b\)</span> 的作用是允许激活函数在输入为零时也能被激活，或者调整激活的阈值。</p>
</section>
<section id="激活函数-activation-functions" class="level3">
<h3 class="anchored" data-anchor-id="激活函数-activation-functions">10.2.2 激活函数 (Activation Functions)</h3>
<p>激活函数为神经网络引入非线性，使得网络能够学习和表示更复杂的函数关系。如果沒有激活函数（或者激活函数是线性的），那么无论神经网络有多少层，其最终输出都只是输入特征的线性组合，等价于一个单层线性模型。</p>
<p>常见的激活函数包括：</p>
<section id="sigmoid-logistic-函数" class="level4">
<h4 class="anchored" data-anchor-id="sigmoid-logistic-函数">10.2.2.1 Sigmoid (Logistic) 函数</h4>
<p><span class="math display">\[ \sigma(z) = \frac{1}{1 + e^{-z}} \]</span></p>
<ul>
<li><strong>输出范围：</strong> (0, 1)</li>
<li><strong>特点：</strong>
<ul>
<li>常用于二分类问题的输出层，可以将输出解释为概率。</li>
<li>在输入值很大或很小时，梯度趋近于0（梯度消失问题），可能导致训练缓慢。</li>
<li>输出不是以0为中心。</li>
</ul></li>
</ul>
<div id="cell-fig-sigmoid" class="cell" data-execution_count="2">
<div class="cell-output cell-output-display">
<div id="fig-sigmoid" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sigmoid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="10-deep-learning-basics_files/figure-html/fig-sigmoid-output-1.png" width="514" height="376" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sigmoid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11.3: Sigmoid 激活函数
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="tanh-双曲正切-函数" class="level4">
<h4 class="anchored" data-anchor-id="tanh-双曲正切-函数">10.2.2.2 Tanh (双曲正切) 函数</h4>
<p><span class="math display">\[ \text{tanh}(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}} = 2 \cdot \text{sigmoid}(2z) - 1 \]</span></p>
<ul>
<li><strong>输出范围：</strong> (-1, 1)</li>
<li><strong>特点：</strong>
<ul>
<li>输出以0为中心，通常比Sigmoid函数在隐藏层中表现更好。</li>
<li>仍然存在梯度消失问题。</li>
</ul></li>
</ul>
<div id="cell-fig-tanh" class="cell" data-execution_count="3">
<div class="cell-output cell-output-display">
<div id="fig-tanh" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-tanh-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="10-deep-learning-basics_files/figure-html/fig-tanh-output-1.png" width="534" height="376" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tanh-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11.4: Tanh 激活函数
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="relu-rectified-linear-unit-修正线性单元" class="level4">
<h4 class="anchored" data-anchor-id="relu-rectified-linear-unit-修正线性单元">10.2.2.3 ReLU (Rectified Linear Unit, 修正线性单元)</h4>
<p><span class="math display">\[ \text{ReLU}(z) = \max(0, z) \]</span></p>
<ul>
<li><strong>输出范围：</strong> <span class="math inline">\([0, \infty)\)</span></li>
<li><strong>特点：</strong>
<ul>
<li><strong>目前在深度学习中非常流行，特别是在隐藏层。</strong></li>
<li>计算简单高效。</li>
<li>在正区域梯度恒为1，有助于缓解梯度消失问题。</li>
<li><strong>Dying ReLU 问题：</strong> 如果输入恒为负，神经元将不再被激活，梯度为0，参数无法更新。</li>
<li>输出不是以0为中心。</li>
</ul></li>
</ul>
<div id="cell-fig-relu" class="cell" data-execution_count="4">
<div class="cell-output cell-output-display">
<div id="fig-relu" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-relu-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="10-deep-learning-basics_files/figure-html/fig-relu-output-1.png" width="510" height="376" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-relu-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11.5: ReLU 激活函数
</figcaption>
</figure>
</div>
</div>
</div>
<p><strong>ReLU的变种：</strong></p>
<ul>
<li><strong>Leaky ReLU:</strong> <span class="math inline">\(f(z) = \max(\alpha z, z)\)</span>，其中 <span class="math inline">\(\alpha\)</span> 是一个小的正常数（如0.01）。允许负输入有一个小的非零梯度，以解决Dying ReLU问题。</li>
<li><strong>Parametric ReLU (PReLU):</strong> <span class="math inline">\(\alpha\)</span> 作为一个可学习的参数。</li>
<li><strong>Exponential Linear Unit (ELU):</strong> 结合了ReLU和Sigmoid/Tanh的优点。</li>
</ul>
</section>
<section id="softmax-函数" class="level4">
<h4 class="anchored" data-anchor-id="softmax-函数">10.2.2.4 Softmax 函数</h4>
<p>Softmax 通常用于多分类问题的输出层。它将一个包含 <span class="math inline">\(K\)</span> 个实数的向量转换为一个 <span class="math inline">\(K\)</span> 维的概率分布向量，其中每个元素表示对应类别的概率，且所有元素之和为1。 对于输入向量 <span class="math inline">\(\mathbf{z} = (z_1, z_2, \dots, z_K)\)</span>，Softmax的输出为： <span class="math display">\[ \text{softmax}(\mathbf{z})_i = \frac{e^{z_i}}{\sum_{j=1}^{K} e^{z_j}} \quad \text{for } i = 1, \dots, K \]</span></p>
<ul>
<li><strong>输出范围：</strong> 每个元素在 (0, 1) 之间，所有元素之和为1。</li>
<li><strong>特点：</strong> 非常适合表示多分类问题的概率输出。</li>
</ul>
</section>
</section>
<section id="神经网络的结构" class="level3">
<h3 class="anchored" data-anchor-id="神经网络的结构">10.2.3 神经网络的结构</h3>
<p>一个典型的全连接神经网络 (Fully Connected Neural Network) 或多层感知机 (Multilayer Perceptron, MLP) 由以下几部分组成：</p>
<ul>
<li><strong>输入层 (Input Layer)：</strong> 接收原始数据（特征）。输入层神经元的数量通常等于输入数据的特征数量。它不进行计算，只是将数据传递给第一隐藏层。</li>
<li><strong>隐藏层 (Hidden Layer(s))：</strong> 位于输入层和输出层之间。这些层执行大部分计算，学习数据的复杂模式和表示。一个神经网络可以有一个或多个隐藏层。深度学习模型通常有多个隐藏层。</li>
<li><strong>输出层 (Output Layer)：</strong> 产生最终的预测结果。输出层神经元的数量和激活函数的选择取决于具体任务：
<ul>
<li><strong>二分类：</strong> 通常一个神经元，使用Sigmoid激活函数。</li>
<li><strong>多分类 (K个类别)：</strong> 通常K个神经元，使用Softmax激活函数。</li>
<li><strong>回归：</strong> 通常一个或多个神经元（取决于预测多少个值），通常不使用激活函数或使用线性激活函数。</li>
</ul></li>
</ul>
<div id="fig-nn-structure" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Neural Network Structure">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-nn-structure-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://media.datacamp.com/legacy/v1725638284/image_bd3b978959.png" class="img-fluid figure-img" alt="Neural Network Structure" width="500">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-nn-structure-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11.6: 神经网络结构示例 (<em>图片来源: <a href="https://www.datacamp.com/tutorial/multilayer-perceptrons-in-machine-learning">Datacamp - Multilayer Perceptrons in Machine Learning</a></em>)
</figcaption>
</figure>
</div>
<p>在一个全连接网络中，每一层的每个神经元都与前一层的所有神经元相连接。</p>
</section>
</section>
<section id="前向传播与反向传播" class="level2">
<h2 class="anchored" data-anchor-id="前向传播与反向传播">10.3 前向传播与反向传播</h2>
<p>神经网络的训练过程主要包括两个阶段：前向传播和反向传播。</p>
<section id="前向传播-forward-propagation" class="level3">
<h3 class="anchored" data-anchor-id="前向传播-forward-propagation">10.3.1 前向传播 (Forward Propagation)</h3>
<p>前向传播是指数据从输入层开始，逐层通过隐藏层，最终到达输出层并产生预测值的过程。</p>
<p>对于网络中的每一层 <span class="math inline">\(l\)</span>： <span class="math display">\[ \mathbf{z}^{[l]} = \mathbf{W}^{[l]} \mathbf{a}^{[l-1]} + \mathbf{b}^{[l]} \]</span> <span class="math display">\[ \mathbf{a}^{[l]} = \sigma^{[l]}(\mathbf{z}^{[l]}) \]</span> 其中：</p>
<ul>
<li><span class="math inline">\(\mathbf{a}^{[l-1]}\)</span> 是第 <span class="math inline">\(l-1\)</span> 层的激活输出（对于第一层，<span class="math inline">\(l=1\)</span>，<span class="math inline">\(\mathbf{a}^{[0]}\)</span> 就是输入数据 <span class="math inline">\(\mathbf{x}\)</span>）。</li>
<li><span class="math inline">\(\mathbf{W}^{[l]}\)</span> 和 <span class="math inline">\(\mathbf{b}^{[l]}\)</span> 分别是第 <span class="math inline">\(l\)</span> 层的权重矩阵和偏置向量。</li>
<li><span class="math inline">\(\sigma^{[l]}\)</span> 是第 <span class="math inline">\(l\)</span> 层的激活函数。</li>
<li><span class="math inline">\(\mathbf{a}^{[l]}\)</span> 是第 <span class="math inline">\(l\)</span> 层的激活输出。</li>
</ul>
<p>这个过程一直持续到输出层，得到最终的预测值 <span class="math inline">\(\hat{\mathbf{y}} = \mathbf{a}^{[L]}\)</span> (假设有L层)。</p>
</section>
<section id="损失函数-loss-function" class="level3">
<h3 class="anchored" data-anchor-id="损失函数-loss-function">10.3.2 损失函数 (Loss Function)</h3>
<p>在得到预测值 <span class="math inline">\(\hat{\mathbf{y}}\)</span> 后，我们需要一个<strong>损失函数 (Loss Function)</strong> 或<strong>成本函数 (Cost Function)</strong> 来衡量预测值与真实标签 <span class="math inline">\(\mathbf{y}\)</span> 之间的差异。损失函数的值越小，表示模型的预测越准确。</p>
<p>常见的损失函数：</p>
<ul>
<li><p><strong>均方误差 (Mean Squared Error, MSE)：</strong> 常用于回归问题。 <span class="math display">\[ L(\mathbf{y}, \hat{\mathbf{y}}) = \frac{1}{m} \sum_{i=1}^{m} (y_i - \hat{y}_i)^2 \]</span> (对于 <span class="math inline">\(m\)</span> 个样本的批量，或者单个样本时 <span class="math inline">\(m=1\)</span>)</p></li>
<li><p><strong>交叉熵损失 (Cross-Entropy Loss)：</strong> 常用于分类问题。</p>
<ul>
<li><strong>二分类交叉熵 (Binary Cross-Entropy)：</strong> (单个样本) <span class="math display">\[ L(y, \hat{y}) = -[y \log(\hat{y}) + (1-y) \log(1-\hat{y})] \]</span> 其中 <span class="math inline">\(y \in \{0, 1\}\)</span> 是真实标签，<span class="math inline">\(\hat{y} \in (0, 1)\)</span> 是模型预测为类别1的概率。</li>
<li><strong>分类交叉熵 (Categorical Cross-Entropy)：</strong> (单个样本，K个类别，使用one-hot编码的真实标签) <span class="math display">\[ L(\mathbf{y}, \hat{\mathbf{y}}) = - \sum_{k=1}^{K} y_k \log(\hat{y}_k) \]</span> 其中 <span class="math inline">\(y_k\)</span> 是真实标签的第k个元素 (0或1)，<span class="math inline">\(\hat{y}_k\)</span> 是模型预测为类别k的概率。</li>
</ul></li>
</ul>
</section>
<section id="反向传播-backward-propagation-与梯度下降" class="level3">
<h3 class="anchored" data-anchor-id="反向传播-backward-propagation-与梯度下降">10.3.3 反向传播 (Backward Propagation) 与梯度下降</h3>
<p>神经网络训练的目标是找到一组权重 <span class="math inline">\(\mathbf{W}\)</span> 和偏置 <span class="math inline">\(\mathbf{b}\)</span>，使得损失函数 <span class="math inline">\(L\)</span> 最小化。这通常通过<strong>梯度下降 (Gradient Descent)</strong> 算法及其变种来实现。</p>
<ol type="1">
<li><strong>计算梯度：</strong> 为了使用梯度下降，我们需要计算损失函数 <span class="math inline">\(L\)</span> 关于每个权重 <span class="math inline">\(w_{ij}^{[l]}\)</span> 和偏置 <span class="math inline">\(b_i^{[l]}\)</span> 的偏导数（梯度）。 <span class="math display">\[ \frac{\partial L}{\partial w_{ij}^{[l]}}, \quad \frac{\partial L}{\partial b_i^{[l]}} \]</span> <strong>反向传播 (Backpropagation)</strong> 算法是一种高效计算这些梯度的方法，由David Rumelhart、Geoffrey Hinton和Ronald Williams在1986年提出，其核心思想后来为深度学习的发展奠定了基础。该算法利用微积分中的链式法则，从输出层开始，逐层向后计算梯度，直到输入层。</li>
</ol>
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p><strong>2024年诺贝尔物理学奖与神经网络：</strong></p>
<p>2024年，诺贝尔物理学奖授予了美国普林斯顿大学的约翰·霍普菲尔德(John Hopfield)和加拿大多伦多大学的杰弗里·欣顿(Geoffrey Hinton)，以表彰他们在神经网络和深度学习领域的开创性贡献。这标志着深度学习理论在物理学界的重要地位获得认可。</p>
<p>霍普菲尔德以其提出的<strong>霍普菲尔德网络</strong>(Hopfield Network)而闻名，这是一种全连接的循环神经网络，为现代神经网络和记忆模型奠定了基础。欣顿则被称为”深度学习教父”，他在反向传播算法、受限玻尔兹曼机(RBM)和深度信念网络等方面做出了里程碑式的工作。</p>
<p>有趣的是，欣顿此前已获得2018年图灵奖(计算机领域的”诺贝尔奖”)，成为少数同时获得诺贝尔奖和图灵奖的科学家之一。这充分体现了神经网络研究在跨学科领域的重要价值。</p>
</div>
</div>
</div>
<ol start="2" type="1">
<li><strong>参数更新：</strong> 计算得到梯度后，按照梯度的反方向更新参数： <span class="math display">\[ w_{ij}^{[l]} \leftarrow w_{ij}^{[l]} - \eta \frac{\partial L}{\partial w_{ij}^{[l]}} \]</span> <span class="math display">\[ b_i^{[l]} \leftarrow b_i^{[l]} - \eta \frac{\partial L}{\partial b_i^{[l]}} \]</span> 其中 <span class="math inline">\(\eta\)</span> 是<strong>学习率 (Learning Rate)</strong>，它控制了每次更新的步长。</li>
</ol>
<p><strong>梯度下降的变种：</strong></p>
<ul>
<li><strong>批量梯度下降 (Batch Gradient Descent)：</strong> 每次更新使用整个训练集的梯度。计算成本高，不适用于大数据集。</li>
<li><strong>随机梯度下降 (Stochastic Gradient Descent, SGD)：</strong> 每次更新只使用训练集中的一个样本计算梯度。更新速度快，但梯度波动大。</li>
<li><strong>小批量梯度下降 (Mini-batch Gradient Descent)：</strong> 每次更新使用一小批 (mini-batch) 样本计算梯度。这是实践中最常用的方法，平衡了计算效率和梯度稳定性。</li>
</ul>
<p><strong>优化器 (Optimizers)：</strong></p>
<p>除了基本的SGD，还有许多更高级的优化算法可以改进梯度下降的性能，例如：</p>
<ul>
<li><strong>Momentum:</strong> 引入动量项，加速梯度下降并减少震荡。</li>
<li><strong>AdaGrad (Adaptive Gradient):</strong> 为不同参数自适应地调整学习率。</li>
<li><strong>RMSprop (Root Mean Square Propagation):</strong> 也是自适应学习率的方法。</li>
<li><strong>Adam (Adaptive Moment Estimation):</strong> 结合了Momentum和RMSprop的优点，是目前非常流行和有效的优化器。</li>
</ul>
</section>
</section>
<section id="构建一个简单的神经网络-使用-kerastensorflow" class="level2">
<h2 class="anchored" data-anchor-id="构建一个简单的神经网络-使用-kerastensorflow">10.4 构建一个简单的神经网络 (使用 Keras/TensorFlow)</h2>
<p>现在，我们将使用 Keras (一个高级神经网络API，通常与TensorFlow后端一起使用) 来构建一个简单的全连接神经网络，用于分类任务。</p>
<div class="callout callout-style-simple callout-tip">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p><strong>主流深度学习框架比较：</strong></p>
<ul>
<li><strong>TensorFlow/Keras：</strong>
<ul>
<li>谷歌开发，工业界应用广泛</li>
<li>Keras作为高级API简化了模型构建</li>
<li>支持移动端和嵌入式部署(TFLite)</li>
<li>强大的可视化工具(TensorBoard)</li>
</ul></li>
<li><strong>PyTorch：</strong>
<ul>
<li>Facebook开发，学术研究首选</li>
<li>动态计算图(即时执行)更灵活</li>
<li>与Python生态无缝集成</li>
<li>丰富的计算机视觉库(torchvision)</li>
</ul></li>
<li><strong>JAX：</strong>
<ul>
<li>谷歌开发，结合NumPy和自动微分</li>
<li>函数式编程范式</li>
<li>适合科研和高性能计算</li>
<li>正在快速发展的新兴框架</li>
</ul></li>
<li><strong>MXNet：</strong>
<ul>
<li>Apache开源项目</li>
<li>支持多语言接口</li>
<li>优秀的分布式训练支持</li>
<li>被AWS选为官方深度学习框架</li>
</ul></li>
<li><strong>PaddlePaddle：</strong>
<ul>
<li>百度开发的国产框架</li>
<li>中文文档和社区支持好</li>
<li>针对中文NLP任务优化</li>
<li>政府和企业级应用广泛</li>
</ul></li>
</ul>
<p><strong>选择建议：</strong></p>
<ul>
<li><strong>工业部署：</strong> TensorFlow/Keras</li>
<li><strong>学术研究：</strong> PyTorch</li>
<li><strong>国产化需求：</strong> PaddlePaddle</li>
<li><strong>高性能计算：</strong> JAX</li>
</ul>
</div>
</div>
</div>
<p>我们将使用Scikit-learn内置的 <code>make_moons</code> 数据集，这是一个简单的二分类问题。</p>
<section id="数据准备" class="level3">
<h3 class="anchored" data-anchor-id="数据准备">10.4.1 数据准备</h3>
<div id="cell-code-nn-data-prep" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_moons</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 生成数据</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> make_moons(n_samples<span class="op">=</span><span class="dv">500</span>, noise<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># 划分训练集和测试集</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>, stratify<span class="op">=</span>y)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co"># 数据标准化</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>X_train_scaled <span class="op">=</span> scaler.fit_transform(X_train)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>X_test_scaled <span class="op">=</span> scaler.transform(X_test)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co"># 可视化数据</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>,<span class="dv">5</span>))</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_train_scaled[:, <span class="dv">0</span>], X_train_scaled[:, <span class="dv">1</span>], c<span class="op">=</span>y_train, cmap<span class="op">=</span><span class="st">'viridis'</span>, edgecolors<span class="op">=</span><span class="st">'k'</span>, label<span class="op">=</span><span class="st">'Train'</span>)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_test_scaled[:, <span class="dv">0</span>], X_test_scaled[:, <span class="dv">1</span>], c<span class="op">=</span>y_test, cmap<span class="op">=</span><span class="st">'coolwarm'</span>, marker<span class="op">=</span><span class="st">'x'</span>, label<span class="op">=</span><span class="st">'Test'</span>)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Make Moons Dataset (Scaled)"</span>)</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Feature 1"</span>)</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Feature 2"</span>)</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.savefig("images/10-deep-learning/make_moons.svg")</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"X_train shape: </span><span class="sc">{</span>X_train_scaled<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"y_train shape: </span><span class="sc">{</span>y_train<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"X_test shape: </span><span class="sc">{</span>X_test_scaled<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"y_test shape: </span><span class="sc">{</span>y_test<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="10-deep-learning-basics_files/figure-html/code-nn-data-prep-output-1.png" id="code-nn-data-prep" width="662" height="449" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>X_train shape: (400, 2)
y_train shape: (400,)
X_test shape: (100, 2)
y_test shape: (100,)</code></pre>
</div>
</div>
</section>
<section id="模型定义-使用-keras-sequential-api" class="level3">
<h3 class="anchored" data-anchor-id="模型定义-使用-keras-sequential-api">10.4.2 模型定义 (使用 Keras Sequential API)</h3>
<p>Keras 提供了多种构建模型的方式，最简单的是 <code>Sequential</code> API，它允许我们按顺序堆叠网络层。</p>
<div id="code-nn-model-define" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow <span class="im">import</span> keras <span class="co"># tf.keras</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 设置随机种子以保证结果可复现</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>tf.random.set_seed(<span class="dv">42</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co"># 定义模型</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> keras.models.Sequential([</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    keras.layers.Dense(units<span class="op">=</span><span class="dv">10</span>, activation<span class="op">=</span><span class="st">'relu'</span>, input_shape<span class="op">=</span>X_train_scaled.shape[<span class="dv">1</span>:]), <span class="co"># 第一个隐藏层，10个神经元，ReLU激活，需要指定输入形状</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    keras.layers.Dense(units<span class="op">=</span><span class="dv">5</span>, activation<span class="op">=</span><span class="st">'relu'</span>),                                      <span class="co"># 第二个隐藏层，5个神经元，ReLU激活</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    keras.layers.Dense(units<span class="op">=</span><span class="dv">1</span>, activation<span class="op">=</span><span class="st">'sigmoid'</span>)                                    <span class="co"># 输出层，1个神经元，Sigmoid激活 (二分类)</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="co"># 打印模型概要</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>model.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="code-nn-model-define-1" class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold">Model: "sequential_3"</span>
</pre>
</div>
<div id="code-nn-model-define-2" class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃<span style="font-weight: bold"> Layer (type)                    </span>┃<span style="font-weight: bold"> Output Shape           </span>┃<span style="font-weight: bold">       Param # </span>┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ dense_9 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                 │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">10</span>)             │            <span style="color: #00af00; text-decoration-color: #00af00">30</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_10 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">5</span>)              │            <span style="color: #00af00; text-decoration-color: #00af00">55</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_11 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">1</span>)              │             <span style="color: #00af00; text-decoration-color: #00af00">6</span> │
└─────────────────────────────────┴────────────────────────┴───────────────┘
</pre>
</div>
<div id="code-nn-model-define-3" class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Total params: </span><span style="color: #00af00; text-decoration-color: #00af00">91</span> (364.00 B)
</pre>
</div>
<div id="code-nn-model-define-4" class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">91</span> (364.00 B)
</pre>
</div>
<div id="code-nn-model-define-5" class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Non-trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">0</span> (0.00 B)
</pre>
</div>
</div>
<p><strong>解释：</strong></p>
<ul>
<li><code>keras.layers.Dense</code>: 创建一个全连接层。
<ul>
<li><code>units</code>: 该层神经元的数量。</li>
<li><code>activation</code>: 该层使用的激活函数。</li>
<li><code>input_shape</code>: 只在第一层需要指定，表示输入数据的形状 (不包括批量大小)。这里 <code>X_train_scaled.shape[1:]</code> 意味着我们取除了第一个维度（样本数）之外的形状，即特征数量。</li>
</ul></li>
</ul>
</section>
<section id="模型编译" class="level3">
<h3 class="anchored" data-anchor-id="模型编译">10.4.3 模型编译</h3>
<p>在训练模型之前，我们需要对其进行编译，这一步会配置模型的学习过程。</p>
<div id="code-nn-model-compile" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    loss<span class="op">=</span><span class="st">'binary_crossentropy'</span>, <span class="co"># 损失函数：二分类交叉熵</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    optimizer<span class="op">=</span><span class="st">'adam'</span>,           <span class="co"># 优化器：Adam</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    metrics<span class="op">=</span>[<span class="st">'accuracy'</span>]        <span class="co"># 评估指标：准确率</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>解释：</strong></p>
<ul>
<li><code>loss</code>: 指定损失函数。对于二分类问题，常用 <code>'binary_crossentropy'</code>。</li>
<li><code>optimizer</code>: 指定优化算法。<code>'adam'</code> 是一个不错的默认选择。也可以传递优化器实例，如 <code>keras.optimizers.Adam(learning_rate=0.001)</code>。</li>
<li><code>metrics</code>: 训练和评估过程中要监控的指标列表。</li>
</ul>
</section>
<section id="模型训练" class="level3">
<h3 class="anchored" data-anchor-id="模型训练">10.4.4 模型训练</h3>
<p>现在我们可以用训练数据来训练模型了。</p>
<div id="cell-code-nn-model-train" class="cell" data-results="hold" data-execution_count="8">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 训练模型</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    X_train_scaled, y_train,</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span><span class="dv">100</span>,                 <span class="co"># 训练轮数 (迭代整个训练集的次数)</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">32</span>,              <span class="co"># 每批样本数量</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    validation_split<span class="op">=</span><span class="fl">0.1</span>,       <span class="co"># 从训练数据中分出10%作为验证集</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">0</span>                   <span class="co"># verbose=1 显示进度条, verbose=0 静默, verbose=2 每轮一行</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="co"># `history` 对象包含了训练过程中的损失和指标值</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(history.history).plot(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">5</span>))</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>plt.gca().set_ylim(<span class="dv">0</span>, <span class="dv">1</span>) <span class="co"># 设置y轴范围</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Model Training History"</span>)</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Epoch"</span>)</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.savefig("images/10-deep-learning/training_history.svg")</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="10-deep-learning-basics_files/figure-html/code-nn-model-train-output-1.png" id="code-nn-model-train" width="645" height="449" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p><strong>解释：</strong></p>
<ul>
<li><code>epochs</code>: 模型将遍历整个训练数据的次数。</li>
<li><code>batch_size</code>: 在每次梯度更新中使用的样本数量。</li>
<li><code>validation_split</code>: 从训练数据中自动划分一部分作为验证集，用于在训练过程中监控模型在未见过数据上的性能。也可以直接提供 <code>validation_data=(X_val, y_val)</code>。</li>
<li><code>verbose</code>: 控制日志输出的详细程度。</li>
</ul>
<p><code>model.fit()</code> 返回一个 <code>History</code> 对象，其中包含了训练过程中的损失值和指定的评估指标值，我们可以用它来绘制学习曲线。</p>
</section>
<section id="模型评估" class="level3">
<h3 class="anchored" data-anchor-id="模型评估">10.4.5 模型评估</h3>
<p>训练完成后，我们在测试集上评估模型的最终性能。</p>
<div id="code-nn-model-evaluate" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>loss, accuracy <span class="op">=</span> model.evaluate(X_test_scaled, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">测试集损失 (Test Loss): </span><span class="sc">{</span>loss<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"测试集准确率 (Test Accuracy): </span><span class="sc">{</span>accuracy<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 进行预测</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>y_pred_proba <span class="op">=</span> model.predict(X_test_scaled, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> (y_pred_proba <span class="op">&gt;</span> <span class="fl">0.5</span>).astype(<span class="st">"int32"</span>) <span class="co"># 将概率转换为类别标签 (0或1)</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 查看一些预测结果</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">部分预测结果 (概率, 预测类别, 真实类别):"</span>)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>y_pred_proba[i][<span class="dv">0</span>]<span class="sc">:.4f}</span><span class="ch">\t</span><span class="sc">{</span>y_pred[i][<span class="dv">0</span>]<span class="sc">}</span><span class="ch">\t</span><span class="sc">{</span>y_test[i]<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
测试集损失 (Test Loss): 0.1343
测试集准确率 (Test Accuracy): 0.9700

部分预测结果 (概率, 预测类别, 真实类别):
0.9856  1   1
0.0119  0   0
0.1585  0   0
0.9908  1   1
0.9615  1   1
0.9164  1   1
0.9631  1   1
0.1139  0   0
0.4994  0   0
0.6153  1   0</code></pre>
</div>
</div>
</section>
<section id="可视化决策边界-可选" class="level3">
<h3 class="anchored" data-anchor-id="可视化决策边界-可选">10.4.6 可视化决策边界 (可选)</h3>
<p>对于二维数据，我们可以可视化模型的决策边界。</p>
<div id="cell-fig-nn-decision-boundary" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_decision_boundary(model, X, y, scaler):</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    x_min, x_max <span class="op">=</span> X[:, <span class="dv">0</span>].<span class="bu">min</span>() <span class="op">-</span> <span class="fl">0.5</span>, X[:, <span class="dv">0</span>].<span class="bu">max</span>() <span class="op">+</span> <span class="fl">0.5</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    y_min, y_max <span class="op">=</span> X[:, <span class="dv">1</span>].<span class="bu">min</span>() <span class="op">-</span> <span class="fl">0.5</span>, X[:, <span class="dv">1</span>].<span class="bu">max</span>() <span class="op">+</span> <span class="fl">0.5</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    xx, yy <span class="op">=</span> np.meshgrid(np.arange(x_min, x_max, <span class="fl">0.02</span>),</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>                         np.arange(y_min, y_max, <span class="fl">0.02</span>))</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 对网格点进行同样的缩放</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>    grid_points <span class="op">=</span> np.c_[xx.ravel(), yy.ravel()]</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>    grid_points_scaled <span class="op">=</span> scaler.transform(grid_points) <span class="co"># 使用之前fit好的scaler</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>    Z <span class="op">=</span> model.predict(grid_points_scaled, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>    Z <span class="op">=</span> (Z <span class="op">&gt;</span> <span class="fl">0.5</span>).astype(<span class="bu">int</span>).reshape(xx.shape)</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>    plt.contourf(xx, yy, Z, alpha<span class="op">=</span><span class="fl">0.4</span>, cmap<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>    plt.scatter(X[:, <span class="dv">0</span>], X[:, <span class="dv">1</span>], c<span class="op">=</span>y, s<span class="op">=</span><span class="dv">20</span>, edgecolor<span class="op">=</span><span class="st">'k'</span>, cmap<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">"Decision Boundary"</span>)</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">"Feature 1 (scaled)"</span>)</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">"Feature 2 (scaled)"</span>)</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>plot_decision_boundary(model, X_train_scaled, y_train, scaler) <span class="co"># 在训练数据上绘制</span></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.savefig("images/10-deep-learning/decision_boundary.svg")</span></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div id="fig-nn-decision-boundary" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-nn-decision-boundary-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="10-deep-learning-basics_files/figure-html/fig-nn-decision-boundary-output-1.png" width="662" height="523" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-nn-decision-boundary-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11.7: 神经网络的决策边界
</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="深度学习中的常见挑战" class="level2">
<h2 class="anchored" data-anchor-id="深度学习中的常见挑战">10.5 深度学习中的常见挑战</h2>
<ul>
<li><strong>过拟合 (Overfitting)：</strong> 深度学习模型由于其复杂性，很容易在训练数据上过拟合。解决方法包括：
<ul>
<li>获取更多数据</li>
<li>数据增强</li>
<li>正则化 (L1, L2)</li>
<li>Dropout</li>
<li>早停 (Early Stopping)</li>
</ul></li>
<li><strong>梯度消失/爆炸 (Vanishing/Exploding Gradients)：</strong> 在深层网络中，梯度在反向传播时可能会变得非常小（消失）或非常大（爆炸），导致训练困难。解决方法包括：
<ul>
<li>合适的权重初始化 (如 He, Xavier/Glorot 初始化)</li>
<li>使用ReLU及其变种激活函数</li>
<li>批量归一化 (Batch Normalization)</li>
<li>梯度裁剪 (Gradient Clipping)</li>
<li>残差连接 (Residual Connections, 例如在ResNet中)</li>
</ul></li>
<li><strong>计算资源需求：</strong> 训练大型深度学习模型通常需要大量的计算资源（GPU/TPU）和时间。</li>
<li><strong>超参数调优：</strong> 深度学习模型有很多超参数（网络结构、学习率、批量大小等），调优它们可能非常耗时。</li>
</ul>
</section>
<section id="本章总结" class="level2">
<h2 class="anchored" data-anchor-id="本章总结">10.6 本章总结</h2>
<p>本章我们初步探索了深度学习的世界：</p>
<ul>
<li>从深度学习与传统机器学习的区别和联系入手，理解了深度学习的核心在于通过深层神经网络自动学习特征。</li>
<li>学习了神经网络的基本单元——神经元模型，以及赋予网络非线性能力的激活函数（Sigmoid, Tanh, ReLU, Softmax）。</li>
<li>了解了神经网络的典型结构：输入层、隐藏层和输出层。</li>
<li>掌握了神经网络训练的核心机制：前向传播计算预测，损失函数衡量误差，反向传播计算梯度，以及梯度下降（及其优化器如Adam）更新参数。</li>
<li>通过一个Keras实例，我们动手构建、编译、训练和评估了一个简单的全连接神经网络，并学会了可视化训练历史和决策边界。</li>
<li>最后，我们简要讨论了深度学习面临的一些常见挑战，如过拟合和梯度问题。</li>
</ul>
<p>这仅仅是深度学习的冰山一角。接下来的章节，我们将学习更专门化、更强大的神经网络架构，如卷积神经网络 (CNN) 和循环神经网络 (RNN)。</p>
</section>
<section id="思考与练习" class="level2">
<h2 class="anchored" data-anchor-id="思考与练习">10.7 思考与练习</h2>
<section id="基础概念回顾" class="level3">
<h3 class="anchored" data-anchor-id="基础概念回顾">10.7.1 基础概念回顾</h3>
<ol type="1">
<li><strong>深度学习与神经网络概览：</strong>
<ul>
<li>什么是深度学习？它与传统机器学习的主要区别是什么？</li>
<li>神经元模型包含哪些主要组成部分？</li>
<li>为什么激活函数在神经网络中是必需的？如果所有激活函数都是线性的，会发生什么？</li>
</ul></li>
<li><strong>激活函数与损失函数：</strong>
<ul>
<li>比较Sigmoid、ReLU和Softmax激活函数的特点和常见用途。</li>
<li>什么是损失函数？列举至少两种常用的损失函数及其适用场景。</li>
</ul></li>
<li><strong>训练与优化：</strong>
<ul>
<li>简述前向传播和反向传播在神经网络训练中的作用。</li>
<li>解释学习率在梯度下降中的作用。学习率过大或过小可能会导致什么问题？</li>
<li>Adam优化器相比SGD有什么优势？</li>
</ul></li>
</ol>
</section>
<section id="keras实践与探索" class="level3">
<h3 class="anchored" data-anchor-id="keras实践与探索">10.7.2 Keras实践与探索</h3>
<p><strong>项目目标：</strong> 动手实践，加深对Keras模型构建、训练、评估和超参数调整的理解。</p>
<p><strong>任务步骤：</strong></p>
<ol type="1">
<li><strong>调整模型结构：</strong> 尝试修改上一节 <code>make_moons</code> 示例中神经网络的结构（例如，改变隐藏层的数量、每层的神经元数量、使用不同的激活函数），观察其对训练过程和最终性能的影响。</li>
<li><strong>比较优化器与学习率：</strong> 在模型编译时尝试使用不同的优化器（如 <code>SGD</code>, <code>RMSprop</code>）和不同的学习率，记录并比较实验结果。</li>
<li><strong>挑战新数据集：</strong> 使用 <code>sklearn.datasets.make_circles</code> 生成另一个非线性可分的数据集，并尝试用类似的神经网络进行分类。调整模型结构和超参数以获得最佳性能，并可视化决策边界。</li>
</ol>
</section>
<section id="深入思考与挑战" class="level3">
<h3 class="anchored" data-anchor-id="深入思考与挑战">10.7.3 深入思考与挑战</h3>
<ol type="1">
<li><strong>ReLU的特性：</strong> ReLU激活函数为什么比Sigmoid或Tanh在深层网络中更受欢迎？它有什么潜在问题（例如Dying ReLU）？Leaky ReLU是如何尝试解决这个问题的？</li>
<li><strong>输出层设计：</strong> 如果一个二分类模型的输出层使用Softmax激活函数（即两个输出神经元，分别代表两个类别的概率），其效果与使用Sigmoid激活函数（一个输出神经元，代表其中一个类别的概率）相比如何？对应的损失函数应该如何选择才能使两者等价或类似？</li>
<li><strong>数据标准化的重要性：</strong> 详细解释为什么数据标准化/归一化在训练神经网络时通常是重要的步骤？它对梯度下降过程有何影响？</li>
<li><strong>(选做) 反向传播手动推导：</strong> 对于一个非常简单的网络（例如，一个输入特征 <span class="math inline">\(x\)</span>，一个隐藏层含一个神经元（激活函数为Sigmoid，权重 <span class="math inline">\(w_1\)</span>，偏置 <span class="math inline">\(b_1\)</span>），一个输出神经元（激活函数为Sigmoid，权重 <span class="math inline">\(w_2\)</span>，偏置 <span class="math inline">\(b_2\)</span>)，损失函数为均方误差 <span class="math inline">\(L = \frac{1}{2}(y - \hat{y})^2\)</span>），尝试手动推导损失函数 <span class="math inline">\(L\)</span> 关于每个权重 (<span class="math inline">\(w_1, w_2\)</span>) 和偏置 (<span class="math inline">\(b_1, b_2\)</span>) 的梯度。这能帮助你更深刻地理解反向传播的原理。</li>
</ol>
</section>
<section id="推荐阅读" class="level3">
<h3 class="anchored" data-anchor-id="推荐阅读">10.7.4 推荐阅读</h3>
<ol type="1">
<li><strong>Chollet, F. (2021). <em>Deep Learning with Python</em> (2nd ed.). Manning Publications.</strong> - Keras作者撰写，非常适合入门和实践。</li>
<li><strong>Goodfellow, I., Bengio, Y., &amp; Courville, A. (2016). <em>Deep Learning</em>. MIT Press.</strong> - 深度学习领域的经典教材，内容全面且深入。可在线阅读：<a href="https://www.deeplearningbook.org/">https://www.deeplearningbook.org/</a></li>
<li><strong>Nielsen, M. A. (2015). <em>Neural Networks and Deep Learning</em>. Determination Press.</strong> - 一本优秀的免费在线书籍，用清晰易懂的方式讲解了神经网络和深度学习的核心概念。可在线阅读：<a href="http://neuralnetworksanddeeplearning.com/">http://neuralnetworksanddeeplearning.com/</a></li>
<li><strong>TensorFlow官方教程和Keras文档：</strong>
<ul>
<li>TensorFlow Core Tutorials: <a href="https://www.tensorflow.org/tutorials">https://www.tensorflow.org/tutorials</a></li>
<li>Keras Guides: <a href="https://keras.io/guides/">https://keras.io/guides/</a></li>
</ul></li>
</ol>
<hr>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
          // default icon
          link.classList.add("external");
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./09-model-evaluation-feature-engineering.html" class="pagination-link" aria-label="模型评估、优化与特征工程">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-title">模型评估、优化与特征工程</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./11-cnn.html" class="pagination-link" aria-label="卷积神经网络 (CNN)">
        <span class="nav-page-text"><span class="chapter-title">卷积神经网络 (CNN)</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>